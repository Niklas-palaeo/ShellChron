# Estimate growth rate variability and round up to nearest higher magnitude of 10 for conservative boundary
GRavest <- max(diff(dat[dat$YEARMARKER == 1,1])) / 365 # Estimate maximum growth rate from yearmarkers
GRavmax <- 10 ^ (ceiling(log(GRavest, 10))) # Round up to nearest higher magnitude of 10
# Find tailored range of temperatures from data
d18Oc_range <- range(dat$d18Oc) # Find d18Oc range in data
if(transfer_function == "KimONeil97"){ # Find temperature range (to be superseded with inverse d18O_model function in later updates)
T_range <- 18.03 * 1000 / (log((d18Oc_range - (0.97002 * rev(range(d18Ow)) - 29.98)) / 1000 + 1) * 1000 + 32.42) - 273.15 # Use Kim and O'Neil (1997) with conversion between VSMOW and VPDB by Brand et al. (2014)
}else if(transfer_function == "GrossmanKu86"){
T_range <-  20.6 - 4.34 * (d18Oc_range - rev(range(d18Ow)) - 0.2) # Use Grossmann and Ku (1986) modified by Dettmann et al. (1999)
}else{
print("ERROR: Supplied transfer function is not recognized")
}
T_max <- max(T_range)
T_amp_max <- 2 * abs(diff(T_range))
# Collate lower boundaries of parameters
parl <- c(
T_amp = 0, # Minimum T amplitude in degrees C
T_pha = 0, # Minimum phase in days
T_av = -4, # Minimum average T in degrees C
G_amp = 0, # Minimum seasonal GR range in um/d
G_pha = 0, # Minimum GR phase in days
G_av = -1 * GRavmax, # Minimum average GR in um/d.
G_skw = 0 # Minimum skew factor
)
# Collate upper boundaries of parameters
paru <- c(
T_amp = round(T_amp_max + 0.5, 0), # Maximum T amplitude in degrees C
T_pha = 365, # Maximum phase in days
T_av = round(T_max + 0.5, 0), # Maximum average T in degrees C
G_amp = 2 * GRavmax, # Maximum seasonal GR range in um/d
G_pha = 365, # Maximum GR phase in days
G_av = GRavmax, # Maximum average GR in um/d (based on conservative boundaries of YEARMARKER indicators)
G_skw = 100 # Maximum skew factor
)
# Set parameters for SCEUA optimization
iniflg = SCEUApar[1] # Flag for initial parameter array (default = 1; included)
ngs = SCEUApar[2] # Number of complexes (sub-populations, default = 25)
maxn = SCEUApar[3] # Maximum number of function evaluations allowed during optimization (default = 10000)
kstop = SCEUApar[4] # Maximum number of evolution loops before convergency (default = 5)
pcento = SCEUApar[5] # Percentage change allowed in function value criterion before stop (default = 0.01)
peps = SCEUApar[6] # Convergence level for parameter set (difference between parameters required for stop; default = 0.01)
i=1
Dsam <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 1]
Osam <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 2]
if(MC > 0){
D_err <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 4] # Optional: include error on D
O_err <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 5] # Optional: include error on d18Oc
}else{
D_err <- rep(0, dynwindow$y)
O_err <- rep(0, dynwindow$y)
MC <- 0
}
if(sinfit){ # If sinusoidal fitting is enabled
sinlist <- sinreg(Dsam, Osam) # Run sinusoidal regression to find initial parameter values
# Estimate starting parameters from regression results
O_av_start <- sinlist[[1]][1] # Export starting value for annual d18O average
O_amp_start <- sinlist[[1]][2] # Export starting value for d18O amplitude
O_pha_start <- sinlist[[1]][4] %% sinlist[[1]][3] # Estimate position (in depth of the first peak in d18O)
O_per_start <- sinlist[[1]][3] # Export starting value for period in distance domain
}else{
O_av_start <- mean(Osam) # Estimate starting value for annual d18O average by mean of d18O in record
O_amp_start <- diff(range(Osam)) / 2 # Estimate starting value for d18O amplitude by half the difference between minimum and maximum d18Oc
O_per_start <- diff(range(Dsam)) # Estimate starting period as thickness of isolated year
O_pha_start <- 0.25 * O_per_start # Set starting phase to one quarter of a cycle if it cannot be estimated from sinusoidal regression
}
if(transfer_function == "KimONeil97"){
T_av_start <- 18.03 * 1000 / (1000 * log((O_av_start - (0.97002 * mean(d18Ow) - 29.98)) / 1000 + 1) + 32.42) - 273.15  # Estimate mean temperature. Use Kim and O'Neil (1997) with conversion between VSMOW and VPDB by Brand et al. (2014)
T_amp_start <- 18.03 * 1000 / (1000 * log((O_av_start - O_amp_start - (0.97002 * mean(d18Ow) - 29.98)) / 1000 + 1) + 32.42) - 273.15 - T_av_start # Estimate temperature amplitude. Use Kim and O'Neil (1997) with conversion between VSMOW and VPDB by Brand et al. (2014)
}else if(transfer_function == "GrossmanKu86"){
T_av_start <- 20.6 - 4.34 * (O_av_start - mean(d18Ow) - 0.2) # Estimate mean temperature. Use Grossmann and Ku (1986) modified by Dettmann et al. (1999)
T_amp_start <- 20.6 - 4.34 * (O_av_start - O_amp_start - mean(d18Ow) - 0.2) - T_av_start # Estimate mean temperature. Use Grossmann and Ku (1986) modified by Dettmann et al. (1999)
}else{
print("ERROR: Supplied transfer function is not recognized")
}
O_peak <- O_pha_start + Dsam[1] # Find position of d18O peak in distance domain
T_pha_start <- ((O_pha_start - 0.5 * O_per_start) %% O_per_start) / O_per_start * T_per # Estimate position of first peak in temperature (low in d18O) relative to annual cycle (days)
G_av_start <- O_per_start / G_per # Estimate average growth rate in distance/day
years <- 3 # Set default number of years to 3
# Collate starting parameters
par0 <- c(
T_amp = T_amp_start,
T_pha = T_pha_start,
T_av = T_av_start,
G_amp = G_av_start / 2, # Start by estimating growth rate changes by half the average
G_pha = T_pha_start, # Start by estimating that the peak in growth rate coincides with the peak in temperature
G_av = G_av_start,
G_skw = 50 # Start with a no skew
)
sceua_list <- rtop::sceua(growth_model,
par0,
T_per = T_per,
G_per = G_per,
years = years,
t_int = t_int,
transfer_function = transfer_function,
d18Ow = d18Ow,
Dsam = Dsam,
Osam = Osam,
t_maxtemp = t_maxtemp,
parl,
paru,
maxn,
kstop,
pcento,
ngs,
iniflg = iniflg,
peps = peps,
implicit = function(pars){sum(pars[4]/2, pars[6]) < 1} # Make sure that the cumulative GR curve is not located below 0 (if G_av < - G_amp / 2)
)
x11(); plot(result[, c(1,2)]); lines(result[, c(1,3)], col = "red")
par1 <- sceua_list[[1]] # Eport parameters of final model
names(par1) <- names(par0)
result <- growth_model(par1, T_per, G_per, years, t_int, transfer_function, d18Ow, Dsam, Osam, t_maxtemp, plot = FALSE, MC, D_err, O_err, return = "result") # Calculate the end result of the best fit
x11(); plot(result[, c(1,2)]); lines(result[, c(1,3)], col = "red")
load("E:/Dropbox/Research/Manuscripts/[Review] GMD - Bivalve age model/ShellChron/data/Virtual_shell.rda")
View(Virtual_shell)
rm(list=ls())
# Function used to linearly subsample data at new depth values
subsample_mean <- function(dailydata, dailydepth, newdepth, plot=FALSE){
newdata <- vector()
for(i in 1:length(newdepth)){ # Loop through all new depth values (samples)
# Find start and end positions of range to average
if(i == 1){
pos1 <- 1 # If first sample of the record, then start position is equal to start of the record (pos1 = 1)
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}else{
if(i == length(newdepth)){
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(dailydepth) # If last sample of the record, then the last position is equal to the end of the record (pos2 = length(dailydepth))
}else{
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}
}
newdata <- append(newdata, mean(dailydata[pos1:pos2])) # Calculate the new data value for each sample by averaging the range of datapoints between start and end position
}
if(plot == TRUE){ # Create plot showing subsampling if requested
dev.new()
plot(dailydepth, dailydata, type = "l")
points(newdepth, newdata, col = "red")
}
return(newdata)
}
# Function for creating d18Oc and D47 data from set of growth conditions and sampling resolution.
# All input data are vectors at daily resolution, except for D, which depends on the sampling resolution and shell length
shellmodel <- function(time, SST, GR, d18Osw, D, AV = FALSE, plot = FALSE){
Dday <- cumsum(GR) # Create vector linking days to depth values
if(AV == FALSE){
SSTnew <- subsample(SST, Dday, D) # Subsample SST along the new sample set
d18Oswnew <- subsample(d18Osw, Dday, D) # Subsample d18Osw along the new sample set
Tynew <- subsample(Ty, Dday, D) # Subsample time (yr) along the new sample set
}else{
SSTnew <- subsample_mean(SST, Dday, D) # Subsample SST along the new sample set using mean values
d18Oswnew <- subsample_mean(d18Osw, Dday, D) # Subsample d18Osw along the new sample set using mean values
Tynew <- subsample_mean(Ty, Dday, D) # Subsample time (yr) along the new sample set using mean values
}
# alpha = exp((18.03*1000/(SSTnew+273.15)-33.42)/1000) # Calculate alpha of calcite fractionation
# d18Osw_PDB = (0.97002*d18Oswnew-29.98) # Convert d18Osw to PDB
# d18Oc = ((alpha * (d18Osw_PDB/1000 + 1)) - 1)*1000
d18Oc <- (exp((18.03 * 1000 / (SSTnew + 273.15) - 33.42) / 1000) * ((0.97002 * d18Oswnew - 29.98) / 1000 + 1) - 1) * 1000 # Calculate d18O of calcite for each sample according to Kim and O'Neil, 1997
D47 <- (0.0449 * 10^6) / (SSTnew + 273.15) ^ 2 + 0.167 # Calculate D47 of calcite for each sample according to Kele et al., 2015 modified by Bernasconi et al., 2018
if(plot == TRUE){ # Create plots of new data if requested
dev.new()
plot(D, d18Oc, col = "blue")
par(new = TRUE)
plot(D, D47, axes = FALSE, bty = "n", xlab = "", ylab = "", col = "red")
axis(side = 4, at = pretty(range(D47)))
}
dat <- cbind(Tynew, D, d18Oc, D47) # Combine new data for export
return(dat) # Return the new depth, d18Oc and D47 series
}
# Set boundary conditions
Td <- seq(1, 6 * 365, 1) # Create timeline of 6 years in days
Ty <- Td / 365 # Convert to years
MAT <- 20 # Set mean annual temperature
Amp <- 10 # Set seasonal amplitude
Sext <- 2 * Amp # Calculate extent of seasonal variability
TSD <- 1.5 # Set the degree of random non-seasonal noise on the SST curve ("weather")
SST <- rnorm(length(Ty), MAT + Amp * sin(2 * pi * Ty), TSD) # Create virtual daily SST data
GR <- rep(10 / 365, length(Ty)) # Set growth rate to 10 mm/yr, create daily GR vector
DSD <- 0.6 # Set the degree of random non-seasonal noise on the d18Osw curve ("salinity fluctuations")
d18Osw <- rnorm(length(Ty), rep(0, length(Ty)), DSD) # Set d18Osw to 0 permille VSMOW, create daily d18Osw vector
SR <- 0.75 # Set uneven sampling resolutions
# Calculate virtual data
Virtual_shell <- as.data.frame(shellmodel(Ty, SST, GR, d18Osw, D, AV = TRUE))
Virtual_shell$D <- Virtual_shell$D * 1000 # Convert to micrometers
Virtual_shell$D_err <- rep(100, length(Virtual_shell[, 1])) # Add uncertainties on D (in mm)
Virtual_shell$d18Oc_err <- rep(0.1, length(Virtual_shell[, 1])) # Add uncertainties on d18Oc (in permille)
View(Virtual_shell)
View(Virtual_shell)
rm(list=ls())
# Generate virtual shell data
# Function used to linearly subsample data at new depth values
subsample_mean <- function(dailydata, dailydepth, newdepth, plot=FALSE){
newdata <- vector()
for(i in 1:length(newdepth)){ # Loop through all new depth values (samples)
# Find start and end positions of range to average
if(i == 1){
pos1 <- 1 # If first sample of the record, then start position is equal to start of the record (pos1 = 1)
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}else{
if(i == length(newdepth)){
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(dailydepth) # If last sample of the record, then the last position is equal to the end of the record (pos2 = length(dailydepth))
}else{
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}
}
newdata <- append(newdata, mean(dailydata[pos1:pos2])) # Calculate the new data value for each sample by averaging the range of datapoints between start and end position
}
if(plot == TRUE){ # Create plot showing subsampling if requested
dev.new()
plot(dailydepth, dailydata, type = "l")
points(newdepth, newdata, col = "red")
}
return(newdata)
}
# Function for creating d18Oc and D47 data from set of growth conditions and sampling resolution.
# All input data are vectors at daily resolution, except for D, which depends on the sampling resolution and shell length
shellmodel <- function(time, SST, GR, d18Osw, D, AV = FALSE, plot = FALSE){
Dday <- cumsum(GR) # Create vector linking days to depth values
if(AV == FALSE){
SSTnew <- subsample(SST, Dday, D) # Subsample SST along the new sample set
d18Oswnew <- subsample(d18Osw, Dday, D) # Subsample d18Osw along the new sample set
Tynew <- subsample(Ty, Dday, D) # Subsample time (yr) along the new sample set
}else{
SSTnew <- subsample_mean(SST, Dday, D) # Subsample SST along the new sample set using mean values
d18Oswnew <- subsample_mean(d18Osw, Dday, D) # Subsample d18Osw along the new sample set using mean values
Tynew <- subsample_mean(Ty, Dday, D) # Subsample time (yr) along the new sample set using mean values
}
# alpha = exp((18.03*1000/(SSTnew+273.15)-33.42)/1000) # Calculate alpha of calcite fractionation
# d18Osw_PDB = (0.97002*d18Oswnew-29.98) # Convert d18Osw to PDB
# d18Oc = ((alpha * (d18Osw_PDB/1000 + 1)) - 1)*1000
d18Oc <- (exp((18.03 * 1000 / (SSTnew + 273.15) - 33.42) / 1000) * ((0.97002 * d18Oswnew - 29.98) / 1000 + 1) - 1) * 1000 # Calculate d18O of calcite for each sample according to Kim and O'Neil, 1997
D47 <- (0.0449 * 10^6) / (SSTnew + 273.15) ^ 2 + 0.167 # Calculate D47 of calcite for each sample according to Kele et al., 2015 modified by Bernasconi et al., 2018
if(plot == TRUE){ # Create plots of new data if requested
dev.new()
plot(D, d18Oc, col = "blue")
par(new = TRUE)
plot(D, D47, axes = FALSE, bty = "n", xlab = "", ylab = "", col = "red")
axis(side = 4, at = pretty(range(D47)))
}
dat <- cbind(Tynew, D, d18Oc, D47) # Combine new data for export
return(dat) # Return the new depth, d18Oc and D47 series
}
# Set boundary conditions
Td <- seq(1, 6 * 365, 1) # Create timeline of 6 years in days
Ty <- Td / 365 # Convert to years
MAT <- 20 # Set mean annual temperature
Amp <- 10 # Set seasonal amplitude
Sext <- 2 * Amp # Calculate extent of seasonal variability
TSD <- 1.5 # Set the degree of random non-seasonal noise on the SST curve ("weather")
SST <- rnorm(length(Ty), MAT + Amp * sin(2 * pi * Ty), TSD) # Create virtual daily SST data
GR <- rep(10 / 365, length(Ty)) # Set growth rate to 10 mm/yr, create daily GR vector
DSD <- 0.6 # Set the degree of random non-seasonal noise on the d18Osw curve ("salinity fluctuations")
d18Osw <- rnorm(length(Ty), rep(0, length(Ty)), DSD) # Set d18Osw to 0 permille VSMOW, create daily d18Osw vector
SR <- 0.75 # Set uneven sampling resolutions
test <- shellmodel(Ty, SST, GR, d18Osw, D, AV = TRUE)
Virtual_shell <- as.data.frame(shellmodel(Ty, SST, GR, d18Osw, D, AV = TRUE))
# Function used to linearly subsample data at new depth values
subsample_mean <- function(dailydata, dailydepth, newdepth, plot=FALSE){
newdata <- vector()
for(i in 1:length(newdepth)){ # Loop through all new depth values (samples)
print(i)
# Find start and end positions of range to average
if(i == 1){
pos1 <- 1 # If first sample of the record, then start position is equal to start of the record (pos1 = 1)
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}else{
if(i == length(newdepth)){
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(dailydepth) # If last sample of the record, then the last position is equal to the end of the record (pos2 = length(dailydepth))
}else{
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}
}
newdata <- append(newdata, mean(dailydata[pos1:pos2])) # Calculate the new data value for each sample by averaging the range of datapoints between start and end position
}
if(plot == TRUE){ # Create plot showing subsampling if requested
dev.new()
plot(dailydepth, dailydata, type = "l")
points(newdepth, newdata, col = "red")
}
return(newdata)
}
# Function for creating d18Oc and D47 data from set of growth conditions and sampling resolution.
# All input data are vectors at daily resolution, except for D, which depends on the sampling resolution and shell length
shellmodel <- function(time, SST, GR, d18Osw, D, AV = FALSE, plot = FALSE){
Dday <- cumsum(GR) # Create vector linking days to depth values
if(AV == FALSE){
SSTnew <- subsample(SST, Dday, D) # Subsample SST along the new sample set
d18Oswnew <- subsample(d18Osw, Dday, D) # Subsample d18Osw along the new sample set
Tynew <- subsample(Ty, Dday, D) # Subsample time (yr) along the new sample set
}else{
SSTnew <- subsample_mean(SST, Dday, D) # Subsample SST along the new sample set using mean values
d18Oswnew <- subsample_mean(d18Osw, Dday, D) # Subsample d18Osw along the new sample set using mean values
Tynew <- subsample_mean(Ty, Dday, D) # Subsample time (yr) along the new sample set using mean values
}
# alpha = exp((18.03*1000/(SSTnew+273.15)-33.42)/1000) # Calculate alpha of calcite fractionation
# d18Osw_PDB = (0.97002*d18Oswnew-29.98) # Convert d18Osw to PDB
# d18Oc = ((alpha * (d18Osw_PDB/1000 + 1)) - 1)*1000
d18Oc <- (exp((18.03 * 1000 / (SSTnew + 273.15) - 33.42) / 1000) * ((0.97002 * d18Oswnew - 29.98) / 1000 + 1) - 1) * 1000 # Calculate d18O of calcite for each sample according to Kim and O'Neil, 1997
D47 <- (0.0449 * 10^6) / (SSTnew + 273.15) ^ 2 + 0.167 # Calculate D47 of calcite for each sample according to Kele et al., 2015 modified by Bernasconi et al., 2018
if(plot == TRUE){ # Create plots of new data if requested
dev.new()
plot(D, d18Oc, col = "blue")
par(new = TRUE)
plot(D, D47, axes = FALSE, bty = "n", xlab = "", ylab = "", col = "red")
axis(side = 4, at = pretty(range(D47)))
}
dat <- cbind(Tynew, D, d18Oc, D47) # Combine new data for export
return(dat) # Return the new depth, d18Oc and D47 series
}
# Set boundary conditions
Td <- seq(1, 6 * 365, 1) # Create timeline of 6 years in days
Ty <- Td / 365 # Convert to years
MAT <- 20 # Set mean annual temperature
Amp <- 10 # Set seasonal amplitude
Sext <- 2 * Amp # Calculate extent of seasonal variability
TSD <- 1.5 # Set the degree of random non-seasonal noise on the SST curve ("weather")
SST <- rnorm(length(Ty), MAT + Amp * sin(2 * pi * Ty), TSD) # Create virtual daily SST data
GR <- rep(10 / 365, length(Ty)) # Set growth rate to 10 mm/yr, create daily GR vector
DSD <- 0.6 # Set the degree of random non-seasonal noise on the d18Osw curve ("salinity fluctuations")
d18Osw <- rnorm(length(Ty), rep(0, length(Ty)), DSD) # Set d18Osw to 0 permille VSMOW, create daily d18Osw vector
SR <- 0.75 # Set uneven sampling resolutions
# Calculate virtual data
Virtual_shell <- as.data.frame(shellmodel(Ty, SST, GR, d18Osw, D, AV = TRUE))
Dday <- cumsum(GR)
DDday
Dday
D
rm(list=ls())
# Function used to linearly subsample data at new depth values
subsample_mean <- function(dailydata, dailydepth, newdepth, plot=FALSE){
newdata <- vector()
for(i in 1:length(newdepth)){ # Loop through all new depth values (samples)
print(i)
# Find start and end positions of range to average
if(i == 1){
pos1 <- 1 # If first sample of the record, then start position is equal to start of the record (pos1 = 1)
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}else{
if(i == length(newdepth)){
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(dailydepth) # If last sample of the record, then the last position is equal to the end of the record (pos2 = length(dailydepth))
}else{
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}
}
newdata <- append(newdata, mean(dailydata[pos1:pos2])) # Calculate the new data value for each sample by averaging the range of datapoints between start and end position
}
if(plot == TRUE){ # Create plot showing subsampling if requested
dev.new()
plot(dailydepth, dailydata, type = "l")
points(newdepth, newdata, col = "red")
}
return(newdata)
}
# Function for creating d18Oc and D47 data from set of growth conditions and sampling resolution.
# All input data are vectors at daily resolution, except for D, which depends on the sampling resolution and shell length
shellmodel <- function(time, SST, GR, d18Osw, D, AV = FALSE, plot = FALSE){
Dday <- cumsum(GR) # Create vector linking days to depth values
if(AV == FALSE){
SSTnew <- subsample(SST, Dday, D) # Subsample SST along the new sample set
d18Oswnew <- subsample(d18Osw, Dday, D) # Subsample d18Osw along the new sample set
Tynew <- subsample(Ty, Dday, D) # Subsample time (yr) along the new sample set
}else{
SSTnew <- subsample_mean(SST, Dday, D) # Subsample SST along the new sample set using mean values
d18Oswnew <- subsample_mean(d18Osw, Dday, D) # Subsample d18Osw along the new sample set using mean values
Tynew <- subsample_mean(Ty, Dday, D) # Subsample time (yr) along the new sample set using mean values
}
# alpha = exp((18.03*1000/(SSTnew+273.15)-33.42)/1000) # Calculate alpha of calcite fractionation
# d18Osw_PDB = (0.97002*d18Oswnew-29.98) # Convert d18Osw to PDB
# d18Oc = ((alpha * (d18Osw_PDB/1000 + 1)) - 1)*1000
d18Oc <- (exp((18.03 * 1000 / (SSTnew + 273.15) - 33.42) / 1000) * ((0.97002 * d18Oswnew - 29.98) / 1000 + 1) - 1) * 1000 # Calculate d18O of calcite for each sample according to Kim and O'Neil, 1997
D47 <- (0.0449 * 10^6) / (SSTnew + 273.15) ^ 2 + 0.167 # Calculate D47 of calcite for each sample according to Kele et al., 2015 modified by Bernasconi et al., 2018
if(plot == TRUE){ # Create plots of new data if requested
dev.new()
plot(D, d18Oc, col = "blue")
par(new = TRUE)
plot(D, D47, axes = FALSE, bty = "n", xlab = "", ylab = "", col = "red")
axis(side = 4, at = pretty(range(D47)))
}
dat <- cbind(Tynew, D, d18Oc, D47) # Combine new data for export
return(dat) # Return the new depth, d18Oc and D47 series
}
# Set boundary conditions
Td <- seq(1, 6 * 365, 1) # Create timeline of 6 years in days
Ty <- Td / 365 # Convert to years
MAT <- 20 # Set mean annual temperature
Amp <- 10 # Set seasonal amplitude
Sext <- 2 * Amp # Calculate extent of seasonal variability
TSD <- 1.5 # Set the degree of random non-seasonal noise on the SST curve ("weather")
SST <- rnorm(length(Ty), MAT + Amp * sin(2 * pi * Ty), TSD) # Create virtual daily SST data
GR <- rep(10 / 365, length(Ty)) # Set growth rate to 10 mm/yr, create daily GR vector
DSD <- 0.6 # Set the degree of random non-seasonal noise on the d18Osw curve ("salinity fluctuations")
d18Osw <- rnorm(length(Ty), rep(0, length(Ty)), DSD) # Set d18Osw to 0 permille VSMOW, create daily d18Osw vector
SR <- 0.75 # Set uneven sampling resolutions
# Set boundary conditions
Td <- seq(1, 6 * 365, 1) # Create timeline of 6 years in days
Ty <- Td / 365 # Convert to years
MAT <- 20 # Set mean annual temperature
Amp <- 10 # Set seasonal amplitude
Sext <- 2 * Amp # Calculate extent of seasonal variability
TSD <- 1.5 # Set the degree of random non-seasonal noise on the SST curve ("weather")
SST <- rnorm(length(Ty), MAT + Amp * sin(2 * pi * Ty), TSD) # Create virtual daily SST data
GR <- rep(10 / 365, length(Ty)) # Set growth rate to 10 mm/yr, create daily GR vector
DSD <- 0.6 # Set the degree of random non-seasonal noise on the d18Osw curve ("salinity fluctuations")
d18Osw <- rnorm(length(Ty), rep(0, length(Ty)), DSD) # Set d18Osw to 0 permille VSMOW, create daily d18Osw vector
SR <- 0.75 # Set uneven sampling resolutions
# Create vector for all samples along entire shell length by applying constant sampling resolution
D <- seq(SR[i], sum(GR), SR[i])
D <- seq(SR, sum(GR), SR)
Virtual_shell <- as.data.frame(shellmodel(Ty, SST, GR, d18Osw, D, AV = TRUE))
View(Virtual_shell)
Virtual_shell$D <- Virtual_shell$D * 1000 # Convert to micrometers
Virtual_shell$D_err <- rep(100, length(Virtual_shell[, 1])) # Add uncertainties on D (in mm)
Virtual_shell$d18Oc_err <- rep(0.1, length(Virtual_shell[, 1])) # Add uncertainties on d18Oc (in permille)
Virtual_shell$D47 <- NULL # D47 data is removed
load("E:/Dropbox/Research/Manuscripts/[Review] GMD - Bivalve age model/ShellChron/data/Virtual_shell.rda")
Virtual_shell$D <- Virtual_shell$D * 1000
Virtual_shell$D_err <- Virtual_shell$D_err * 1000
rm(list=ls9)
rm(list=ls())
# Function used to linearly subsample data at new depth values
subsample_mean <- function(dailydata, dailydepth, newdepth, plot=FALSE){
newdata <- vector()
for(i in 1:length(newdepth)){ # Loop through all new depth values (samples)
print(i)
# Find start and end positions of range to average
if(i == 1){
pos1 <- 1 # If first sample of the record, then start position is equal to start of the record (pos1 = 1)
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}else{
if(i == length(newdepth)){
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(dailydepth) # If last sample of the record, then the last position is equal to the end of the record (pos2 = length(dailydepth))
}else{
pos1 <- length(which((newdepth[i - 1] + newdepth[i]) / 2 > dailydepth)) # Start position is equal to the middle between the sample depth and the depth of the previous sample
pos2 <- length(which((newdepth[i + 1] + newdepth[i]) / 2 > dailydepth)) # End position is equal to the middle between the sample depth and the depth of the next sample
}
}
newdata <- append(newdata, mean(dailydata[pos1:pos2])) # Calculate the new data value for each sample by averaging the range of datapoints between start and end position
}
if(plot == TRUE){ # Create plot showing subsampling if requested
dev.new()
plot(dailydepth, dailydata, type = "l")
points(newdepth, newdata, col = "red")
}
return(newdata)
}
# Function for creating d18Oc and D47 data from set of growth conditions and sampling resolution.
# All input data are vectors at daily resolution, except for D, which depends on the sampling resolution and shell length
shellmodel <- function(time, SST, GR, d18Osw, D, AV = FALSE, plot = FALSE){
Dday <- cumsum(GR) # Create vector linking days to depth values
if(AV == FALSE){
SSTnew <- subsample(SST, Dday, D) # Subsample SST along the new sample set
d18Oswnew <- subsample(d18Osw, Dday, D) # Subsample d18Osw along the new sample set
Tynew <- subsample(Ty, Dday, D) # Subsample time (yr) along the new sample set
}else{
SSTnew <- subsample_mean(SST, Dday, D) # Subsample SST along the new sample set using mean values
d18Oswnew <- subsample_mean(d18Osw, Dday, D) # Subsample d18Osw along the new sample set using mean values
Tynew <- subsample_mean(Ty, Dday, D) # Subsample time (yr) along the new sample set using mean values
}
# alpha = exp((18.03*1000/(SSTnew+273.15)-33.42)/1000) # Calculate alpha of calcite fractionation
# d18Osw_PDB = (0.97002*d18Oswnew-29.98) # Convert d18Osw to PDB
# d18Oc = ((alpha * (d18Osw_PDB/1000 + 1)) - 1)*1000
d18Oc <- (exp((18.03 * 1000 / (SSTnew + 273.15) - 33.42) / 1000) * ((0.97002 * d18Oswnew - 29.98) / 1000 + 1) - 1) * 1000 # Calculate d18O of calcite for each sample according to Kim and O'Neil, 1997
D47 <- (0.0449 * 10^6) / (SSTnew + 273.15) ^ 2 + 0.167 # Calculate D47 of calcite for each sample according to Kele et al., 2015 modified by Bernasconi et al., 2018
if(plot == TRUE){ # Create plots of new data if requested
dev.new()
plot(D, d18Oc, col = "blue")
par(new = TRUE)
plot(D, D47, axes = FALSE, bty = "n", xlab = "", ylab = "", col = "red")
axis(side = 4, at = pretty(range(D47)))
}
dat <- cbind(Tynew, D, d18Oc, D47) # Combine new data for export
return(dat) # Return the new depth, d18Oc and D47 series
}
# Set boundary conditions
Td <- seq(1, 6 * 365, 1) # Create timeline of 6 years in days
Ty <- Td / 365 # Convert to years
MAT <- 20 # Set mean annual temperature
Amp <- 10 # Set seasonal amplitude
Sext <- 2 * Amp # Calculate extent of seasonal variability
TSD <- 1.5 # Set the degree of random non-seasonal noise on the SST curve ("weather")
SST <- rnorm(length(Ty), MAT + Amp * sin(2 * pi * Ty), TSD) # Create virtual daily SST data
GR <- rep(10 / 365, length(Ty)) # Set growth rate to 10 mm/yr, create daily GR vector
DSD <- 0.6 # Set the degree of random non-seasonal noise on the d18Osw curve ("salinity fluctuations")
d18Osw <- rnorm(length(Ty), rep(0, length(Ty)), DSD) # Set d18Osw to 0 permille VSMOW, create daily d18Osw vector
SR <- 0.75 # Set uneven sampling resolutions
# Create vector for all samples along entire shell length by applying constant sampling resolution
D <- seq(SR, sum(GR), SR)
# Calculate virtual data
Virtual_shell <- as.data.frame(shellmodel(Ty, SST, GR, d18Osw, D, AV = TRUE))
Virtual_shell$D <- Virtual_shell$D * 1000 # Convert to micrometers
Virtual_shell$D_err <- rep(100, length(Virtual_shell[, 1])) # Add uncertainties on D (in mm)
Virtual_shell$d18Oc_err <- rep(0.1, length(Virtual_shell[, 1])) # Add uncertainties on d18Oc (in permille)
Virtual_shell$D47 <- NULL # D47 data is removed
View(Virtual_shell)
Virtual_shell$YEARMARKER <- rep(0, nrow(Virtual_shell))
Virtual_shell$YEARMARKER[c(10, 23, 37, 50, 64, 77)] <- 1
?save
save(Virtual_shell, file = "E:\Dropbox\Research\Manuscripts\[Review] GMD - Bivalve age model\ShellChron\data\Virtual_shell.rda")
save(Virtual_shell, file = "E:/Dropbox/Research/Manuscripts/[Review] GMD - Bivalve age model/ShellChron/data/Virtual_shell.rda")
rm(list=ls())
load("E:/Dropbox/Research/Manuscripts/[Review] GMD - Bivalve age model/ShellChron/data/Virtual_shell.rda")
>data_import
?data_import
