years = 1, # Default number of years of the record = 1
t_int = 1 # Default time interval = 1 day
){
G_amp <- G_par[1] # Seasonal range in Growth rate (um/d)
G_per <- G_par[2] # Period of growth rate seasonality (days)
G_pha <- G_par[3] # Timing of peak in growth rate (day of the year)
G_av <- G_par[4] # Annual average growth rate (um/d)
G_skw <- G_par[5] # Skewness factor in growth rate sinusoid (-)
t <- seq(0, G_per, t_int) # Define time axis based on the number of days in
# a year and the time interval
GR <- rep(NA, length(t)) # Create empty growth rate vector
# Build GR vector piece by piece based on parameters
# Check if t is between the time of maximum growth and the subsequent time
# of minimum growth but before the peak, add one period's length if it is
if(length(t[(((t - G_pha) %% G_per) < (G_per * (100 - G_skw) / 100)) &
(t < G_pha)]) > 0){ # Catch "replacement has length zero" errors
GR[(((t - G_pha) %% G_per) < (G_per * (100 - G_skw) / 100)) &
(t < G_pha)] <- G_av + G_amp/2 * sin(2 * pi * (t[(((t - G_pha) %%
G_per) < (G_per * (100 - G_skw) / 100)) & (t < G_pha)] +
G_per - G_pha + (G_per * (100 - G_skw) / 50) / 4) /
(G_per * (100 - G_skw) / 50))
}
# Check if t is between the time of maximum growth and the subsequent time
# of minimum growth but still after the peak
if(length(t[(((t - G_pha) %% G_per) < (G_per * (100 - G_skw) / 100)) &
(t >= G_pha)]) > 0){ # Catch "replacement has length zero" errors
GR[(((t - G_pha) %% G_per) < (G_per * (100 - G_skw) / 100)) &
(t >= G_pha)] <- G_av + G_amp/2 * sin(2 * pi * (t[(((t - G_pha) %%
G_per) < (G_per * (100 - G_skw) / 100)) & (t >= G_pha)] -
G_pha + (G_per * (100 - G_skw) / 50) / 4) / (G_per *
(100 - G_skw) / 50))
}
# Check if t is between the time of maximum growth and the previous time of
# minimum growth but still before the peak, subtract one period's length if
# it is
if(length(t[(((t - G_pha) %% G_per) >= (G_per * (100 - G_skw) / 100)) &
(t > G_pha)]) > 0){
GR[(((t - G_pha) %% G_per) >= (G_per * (100 - G_skw) / 100)) &
(t > G_pha)] <- G_av + G_amp/2 * sin(2 * pi * (t[(((t - G_pha) %%
G_per) >= (G_per * (100 - G_skw) / 100)) & (t > G_pha)] -
G_per - G_pha + (G_per * G_skw / 50) / 4) /
(G_per * G_skw / 50))
}
if(length(t[(((t - G_pha) %% G_per) >= (G_per * (100 - G_skw) / 100)) &
(t <= G_pha)]) > 0){
GR[(((t - G_pha) %% G_per) >= (G_per * (100 - G_skw) / 100)) &
(t <= G_pha)] <- G_av + G_amp/2 * sin(2 * pi * (t[(((t - G_pha) %%
G_per) >= (G_per * (100 - G_skw) / 100)) & (t <= G_pha)] -
G_pha + (G_per * G_skw / 50) / 4) / (G_per * G_skw / 50))
}
# Replace negative growth rates with zeroes
GR[GR < 0] <- 0
# Multiply t and GR with number of years
if(years > 1){
t <- c(t, rep(t[-1], years - 1) + rep(seq(365, 365 * (years - 1), 365),
each = 365))
GR <- c(GR, rep(GR[-1], years - 1))
}
# Collate results and export
res <- cbind(t, GR)
return(res)
}
mc_err_orth <- function(x, x_err, y, y_err, X, Y, MC){ # Function to propagate
# combined errors on x and y on the modelled X and Y values by means of
# orthogonal projection of x and y uncertainty on the model curve
xmat <- matrix(rnorm(MC * length(x)), nrow = length(x)) * x_err +
matrix(rep(x, MC), nrow = length(x)) # Create matrix of simulated
# X values
ymat <- matrix(rnorm(MC * length(y)), nrow = length(y)) * y_err +
matrix(rep(y, MC), nrow = length(y)) # Create matrix of simulated
# Y values
Xarray <- sqrt( # create array of the length of vectors connecting each MC
# simulated x-y pair and each modelled X-Y pair.
((outer(xmat, X, FUN = "-") - mean(outer(xmat, X, FUN = "-"))) /
sd(outer(xmat, X, FUN = "-"))) ^ 2 + # Square of the normalized
# difference between MC-simulated X values and modelled D
((outer(ymat, Y[, 2], FUN = "-") - mean(outer(ymat, Y[, 2],
FUN = "-"))) / sd(outer(ymat, Y[, 2], FUN = "-"))) ^ 2
# Square of the normalized difference between MC-simulated y values
# and modelled Y values
)
posmat <- apply(Xarray, c(1,2), which.min) # For each MC-simulated x-y pair,
# find the position of the closest model value
Xsimmat <- matrix(X[posmat], nrow = length(x)) # Find the X value that
# belongs to each position in posmat
X_comb <- apply(Xsimmat, 1, mean) # calculate the mean value in X domain
# resulting from orthogonal projection of errors on X and Y from variability
# within the X values
Ysimmat <- matrix(Y[posmat, 2], nrow = length(y)) # Find the Y value that
# belongs to each position in posmat
Y_comb <- approx( # Interpolate modelled temperature values to positions
# along the record.
x = X,
y = Y[, 2],
xout = X_comb,
method = "linear",
rule = 2
)
# Y_comb <- apply(Ysimmat, 1, mean) # calculate the mean value in Y domain
# resulting from orthogonal projection of errors on X and Y from variability
# within the X values
X_err_comb <- apply(Xsimmat, 1, sd) # calculate the standard deviation in X
# domain resulting from orthogonal projection of errors on X and Y from
# variability within the X values
Y_err_comb <- apply(Ysimmat, 1, sd) # calculate the standard deviation in Y
# domain resulting from orthogonal projection of errors on X and Y from
# variability within the X values
result <- data.frame(
X = X_comb,
X_err = X_err_comb,
Y = Y_comb$y,
Y_err = Y_err_comb
)
return(result)
}
mc_err_form <- function(x, x_err, y, y_err, X, Y, MC){
xmat <- matrix(rnorm(MC * length(x)), nrow = length(x)) * x_err +
matrix(rep(x, MC), nrow = length(x)) # Create matrix of simulated
# X values
Xpos <- apply(abs(outer(xmat, X, FUN = "-")), c(1,2), which.min) # find
# closest position in X vector (day) for each simulated X value
Xpos_stat <- cbind(rowMeans(Xpos), apply(Xpos, 1, sd)) # Find mean and
# standard deviation of positions in X vector (day) for each sample
ymat <- matrix(rnorm(MC * length(y)), nrow = length(y)) * y_err +
matrix(rep(Y[Xpos_stat[, 1], 2], MC), nrow = length(y)) # Create matrix
# of Monte Carlo simulated Y values projected on the X-Y curve
Xpos_mat <- outer(round(Xpos_stat[, 1]), seq(-20, 20, 1), "+") %%
length(D) + 1 # Create matrix of D positions around the mean position
# for each sample to match with simulated Y values.
# Window is +/- 20 positions
Xpos_matO <- matrix(Y[Xpos_mat, 2], nrow = length(x)) # Find Y values for
# each position in Xpos_mat
Xpos_matO2 <- apply(outer(Xpos_matO, ymat, FUN = "-"), c(2,4), diag) # Match
# and subtract each simulated Y value with the local environment of Y values
# in the X-Y curve
Ypos <- apply(abs(Xpos_matO2), c(1, 3), which.min) + Xpos_stat[, 1] # Find
# the position of the closest Y value in the Y window (Xpos_matO) for each
# Y simulation
Ypos_stat <- cbind(rowMeans(Ypos), apply(Ypos, 1, sd)) # Find mean and
# standard deviation of positions in X vector (day) for each sample
Ypos_stat[which(Ypos_stat[, 2] == 0), 2] <- sd(seq(-20, 20, 1)) # If SD of
# Y falls outside the window of +/- 20 positions SD is assumed to be equal
# to that of the uniform distribution
pos_err_comb <- sqrt(Ypos_stat[, 2] ^ 2 + Xpos_stat[, 2] ^ 2) # Find
# combined error on position (day)
Xpos_minmax <- cbind(Xpos_stat[, 1] - pos_err_comb, Xpos_stat[, 1] +
pos_err_comb) %% length(D) # Find min and max position values
Xminmax <- matrix(approx(x = X, xout = Xpos_minmax, rule = 2)$y, ncol = 2)
# Find associated D values (linear interpolation)
x_err_comb <- 0.5 * ((Xminmax[,2] - Xminmax[,1]) %% X[length(X)]) # Find
# combined SD in D domain
return(x_err_comb)
}
mc_err_proj <- function(x, x_err, y, y_err, X, Y, MC){ # Function to propagate
# combined errors on x and y on the modelled X and Y values by means of local
# projection of y uncertainty on x and subsequent combination of uncertainties
# in X domain
dYdX <- diff(Y[, 2]) / diff(X) # Create first derivative of Y by X
dYdX[which(abs(dYdX) <= 10 ^ (floor(log(mean(abs(dYdX)), 10)) - 1))] <-
sign(dYdX[which(abs(dYdX) <= 10 ^ (floor(log(mean(abs(dYdX)),
10)) - 1))]) * 10 ^ (floor(log(mean(abs(dYdX)), 10)) - 1) # Remove
# small absolute values (more than one order of magnitude smaller
# than the mean), preserving their sign
dYdX <- append(dYdX, dYdX[length(dYdX)]) # repeat last value to increase the
# length of the vector to match X/Y (366 days)
localslope <- dYdX[apply(abs(outer(x, X, FUN = "-")), 1, which.min)] # Find
# the local slope belonging to each sample position
x_err_proj <- y_err / localslope # Project uncertainty on Y on x domain
# using slope
x_err_comb <- sqrt(x_err_proj ^2 + x_err ^2) # Combine uncertainties on x
# and y in the X domain
return(x_err_comb)
}
View(d18O_model)
sinreg <- function(x, # Function to perform sinusoid regression meant to
# estimate the starting parameters for fitting growth and temperature sinusoids
y,
plot = FALSE # Plot results?
){
Ots <- ts(y) # Turn y into a time series
ssp <- spectrum(Ots, plot = FALSE) # Create periodogram of y
Nper <- 1 / ssp$freq[ssp$spec == max(ssp$spec)] # Estimate period in terms
# of sample number
Dper <- Nper * diff(range(x)) / length(x) # Convert period to depth domain
sinlm <- lm(y ~ sin(2 * pi / Dper * x) + cos(2 * pi / Dper * x)) # Run
# linear model, cutting up d18O = Asin(2 * pi * D) into
# d18O = asin(D) + bcos(D)
sinm <- sinlm$fitted # Extract model result
if(plot == TRUE){
dev.new()
plot(x, y); lines(x, sinm, col = "red")
}
coeff <- summary(sinlm)[["coefficients"]] # Extract a, b and intercept +
# uncertainties
# Calculate coefficients of the form d18O = I + Asin(2 * pi * D + p)
I <- coeff[1, 1] # Intercept (mean annual value)
A <- sqrt(coeff[2, 1] ^ 2 + coeff[3, 1] ^ 2) # Amplitude of seasonality
phase <- -acos(coeff[2, 1] / A) # Phase of sinusoid
peak <- (0.25 + (phase / (2 * pi))) * Dper # timing of seasonal peak
R2adj <- summary(sinlm)$adj.r.squared # Goodness of model fit (adjusted R2)
p <- as.numeric(pf(summary(sinlm)$fstatistic[1],
summary(sinlm)$fstatistic[2],
summary(sinlm)$fstatistic[3],
lower.tail = F)) # p-value of model
return(list(c(I, A, Dper, peak, R2adj, p), sinm)) # Return results of
# regression
}
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::install()
devtools::check()
devtools::check()
devtools::check()
devtools::document()
devtools::install()
devtools::document()
devtools::document()
warnings()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::install()
devtools::document()
devtools::install()
devtools::install()
devtools::install()
devtools::install()
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
install.packages(c("callr", "cli", "clipr", "cpp11", "digest", "DT", "ps", "readr", "sp", "tibble"))
devtools::install()
devtools::check()
require(ShellChron)
# Input details on records
#path <- "E://Dropbox//Research//postdoc//Side projects//Bivalve age model//Case1_HR_results_new" # For Home PC (both)
path <- "C://Users//niels//Dropbox//Research//Manuscripts//Bivalve age model//tests//Gagan_coral_new" # For laptop
setwd(path)
file_name <- "Gagan1993.csv" # Give file name (don't forget to add the extention, should be in CSV format)
mineral <- "aragonite" # Set mineralogy of the record
t_int <- 1 # Set time interval in days
G_per <- T_per <- 365 # Set annual time period in days (default = 365)
#Texel_data <- read.csv("Texel_daily_data.csv", header = T)
# d18Ow <- read.csv("d18Osw.csv", header = FALSE)$V1 # Create d18Ow vector for one year (default = all zero)
d18Ow <- 0.45
t_maxtemp <- 182.5 # Assume taht the day of maximum temperature is halfway through the year.
MC <- 1000
agecorrection <- FALSE
plot <- TRUE
plot_export <- TRUE
export_raw <- TRUE
wrap_function(path, # Wrapping function for the entire model package
file_name, # Give file name (don't forget to add the extention, should be in CSV format)
mineral = "aragonite", # Set mineralogy of the record, default is calcite. Aragonite is also supported
t_int = 1, # Set time interval in days
T_per = 365, # Set annual time period in days (default = 365)
d18Ow = 0.45, # Set d18Ow value or vector (default = constant year-round at 0 VSMOW). Alternative options are either one value (assumed constant year-round) or a vector with length T_per / t_int and interval t_int specifying d18Ow evolution through one year.
t_maxtemp = 182.5, # Define the day of the year at which temperature is heighest. Default = Assume that the day of maximum temperature is helfway through the year
MC = 1000, # Number of MC simulations to include measurement error into error analysis. Default = 1000 (if MC = 0, error on D and d18O measurements not considered)
plot = TRUE, # Should intermediate plots be given to track progress? WARNING: plotting makes the script much slower, especially for long datasets.
plot_export = TRUE, # Should a plot of the results be saved as PDF?
export_raw = FALSE # Should the results of all individual model runs be exported as CSV files?
)
setwd(path)
importlist <- data_import(file_name)
dat <- importlist[[1]]
dynwindow <- importlist[[2]]
G_per <- T_per
View(dat)
resultlist <- Run_model(dat, dynwindow, mineral, d18Ow, T_per, G_per, t_int, t_maxtemp, MC, agecorrection, plot = TRUE)
resultlist <- run_model(dat, dynwindow, mineral, d18Ow, T_per, G_per, t_int, t_maxtemp, MC, agecorrection, plot = TRUE)
setwd(path)
importlist <- data_import(file_name)
dat <- importlist[[1]]
dynwindow <- importlist[[2]]
G_per <- T_per
View(dat)
colnames(D)
colnames(dat)
colnames(dat)[1]<-"D"
resultlist <- run_model(dat, dynwindow, mineral, d18Ow, T_per, G_per, t_int, t_maxtemp, MC, agecorrection, plot = TRUE)
View(dynwindow)
setwd(path)
importlist <- data_import(file_name)
dat <- importlist[[1]]
dynwindow <- importlist[[2]]
G_per <- T_per
View(dat)
colnames(dat)[1]<-"D"
View(dat)
resultlist <- run_model(dat, dynwindow, mineral, d18Ow, T_per, G_per, t_int, t_maxtemp, MC, agecorrection, plot = TRUE)
# Input details on records
path <- "E://Dropbox//Research//Manuscripts//Bivalve age model//tests//Gagan_coral_new" # For Home PC (both)
#path <- "C://Users//niels//Dropbox//Research//Manuscripts//Bivalve age model//tests//Gagan_coral_new" # For laptop
setwd(path)
file_name <- "Gagan1993.csv" # Give file name (don't forget to add the extention, should be in CSV format)
mineral <- "aragonite" # Set mineralogy of the record
t_int <- 1 # Set time interval in days
G_per <- T_per <- 365 # Set annual time period in days (default = 365)
#Texel_data <- read.csv("Texel_daily_data.csv", header = T)
# d18Ow <- read.csv("d18Osw.csv", header = FALSE)$V1 # Create d18Ow vector for one year (default = all zero)
d18Ow <- 0.45
t_maxtemp <- 182.5 # Assume taht the day of maximum temperature is halfway through the year.
MC <- 1000
agecorrection <- FALSE
plot <- TRUE
plot_export <- TRUE
export_raw <- TRUE
# Input details on records
path <- "E://Dropbox//Research//Manuscripts//Bivalve age model//tests//Gagan_coral_new" # For Home PC (both)
#path <- "C://Users//niels//Dropbox//Research//Manuscripts//Bivalve age model//tests//Gagan_coral_new" # For laptop
setwd(path)
file_name <- "Gagan1993.csv" # Give file name (don't forget to add the extention, should be in CSV format)
mineral <- "aragonite" # Set mineralogy of the record
t_int <- 1 # Set time interval in days
G_per <- T_per <- 365 # Set annual time period in days (default = 365)
#Texel_data <- read.csv("Texel_daily_data.csv", header = T)
# d18Ow <- read.csv("d18Osw.csv", header = FALSE)$V1 # Create d18Ow vector for one year (default = all zero)
d18Ow <- 0.45
t_maxtemp <- 182.5 # Assume taht the day of maximum temperature is halfway through the year.
MC <- 1000
agecorrection <- FALSE
plot <- TRUE
plot_export <- TRUE
export_raw <- TRUE
setwd(path)
importlist <- data_import(file_name)
dat <- importlist[[1]]
dynwindow <- importlist[[2]]
G_per <- T_per # Period of growth rate sinusoid should equal that of the temperature sinusoid (which is given)
require(ShellChron)
path <- "C://Users//niels//Dropbox//Research//Manuscripts//Bivalve age model//tests//Gagan_coral_new" # For laptop
setwd(path)
file_name <- "Gagan1993.csv" # Give file name (don't forget to add the extention, should be in CSV format)
mineral <- "aragonite" # Set mineralogy of the record
t_int <- 1 # Set time interval in days
G_per <- T_per <- 365 # Set annual time period in days (default = 365)
#Texel_data <- read.csv("Texel_daily_data.csv", header = T)
# d18Ow <- read.csv("d18Osw.csv", header = FALSE)$V1 # Create d18Ow vector for one year (default = all zero)
d18Ow <- 0.45
t_maxtemp <- 182.5 # Assume taht the day of maximum temperature is halfway through the year.
MC <- 1000
agecorrection <- FALSE
plot <- TRUE
plot_export <- TRUE
export_raw <- TRUE
require(ShellChron)
setwd(path)
importlist <- data_import(file_name)
dat <- importlist[[1]]
dynwindow <- importlist[[2]]
G_per <- T_per # Period of growth rate sinusoid should equal that of the temperature sinusoid (which is given)
View(dat)
colnames(dat)[1]<-"D"
resultlist <- run_model(dat, dynwindow, mineral, d18Ow, T_per, G_per, t_int, t_maxtemp, MC, agecorrection, plot = TRUE)
# Prepare data arrays for storage of modelling results
resultarray <- array( # Create array to contain all modelling results of overlapping windows
rep(as.matrix(cbind(dat, matrix(NA, ncol = length(dynwindow$x), nrow = length(dat$D)))), 9), # Replicate matrix of dat + extra columns to contain all variables
dim = c(length(dat$D), length(dynwindow$x) + length(dat[1,]), 9) # Six variables, being: Modelled d18O, residuals, Day of the Year, Growth between datapoints, Instantaneous growth rate at datapoint and Modelled temperature
)
parmat <- matrix(NA, nrow = 7, ncol = length(dynwindow$x)) # Matrix in which to store the modelling parameters
colnames(parmat) <- dynwindow$x
rownames(parmat) <- c("T_amp", "T_pha", "T_av", "G_amp", "G_pha", "G_av", "G_skw")
# Prepare plot to show model progress
if(plot == TRUE){
dev.new()
fitplot <- ggplot2::ggplot(dat, ggplot2::aes(D, d18Oc)) + # Create a plot showing the fit of each window on the original data, start with a plot of the original data
ggplot2::geom_point() +
ggplot2::geom_line() +
ggplot2::geom_errorbar(ggplot2::aes(ymin = d18Oc - d18Oc_err, # Add error bars on model result (1 SD)
ymax = d18Oc + d18Oc_err),
width = dat$D_err) +
ggplot2::geom_errorbarh(ggplot2::aes(xmin = D - D_err,
xmax = D + D_err),
height = 0.05) +
ggplot2::ggtitle("Plot of d18Oc values vs. depth. Black = data, Red = model, Errorbars = 1 SD")
plot(fitplot)
}
# Estimate growth rate variability and round up to nearest multiple of 100 for conservative boundary
GRavmax <- ceiling(max(diff(dat[dat$YEARMARKER == 1,1])) / 365 / 100) * 100
# Collate lower boundaries of parameters
parl <- c(
T_amp = 0, # Minimum T amplitude in degrees C
T_pha = 0, # Minimum phase in days
T_av = -4, # Minimum average T in degrees C
G_amp = 0, # Minimum seasonal GR range in um/d
G_pha = 0, # Minimum GR phase in days
G_av = -1 * GRavmax, # Minimum average GR in um/d.
G_skw = 0 # Minimum skew factor
)
# Collate upper boundaries of parameters
paru <- c(
T_amp = 15, # Maximum T amplitude in degrees C
T_pha = 365, # Maximum phase in days
T_av = 30, # Maximum average T in degrees C
G_amp = 2 * GRavmax, # Maximum seasonal GR range in um/d
G_pha = 365, # Maximum GR phase in days
G_av = GRavmax, # Maximum average GR in um/d (based on conservative boundaries of YEARMARKER indicators)
G_skw = 100 # Maximum skew factor
)
# Set parameters for SCEUA optimization
iniflg = 1 # Flag for initial parameter array (1 = included)
ngs = 25 # Number of complexes (sub-populations)
maxn = 10000 # Maximum number of function evaluations allowed during optimization
kstop = 5 # Maximum number of evolution loops before convergency
pcento = 0.01 # Percentage change allowed in function value criterion before stop
peps = 0.01 # Convergence level for parameter set (difference between parameters required for stop)
i=1
parl
paru
GRavmax
max(diff(dat[dat$YEARMARKER == 1,1]))
max(diff(dat[dat$YEARMARKER == 1,1]))/365
# Isolate year of d18O data based on window data
Dsam <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 1]
Osam <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 2]
if(MC > 0){
D_err <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 4] # Optional: include error on D
O_err <- dat[dynwindow$x[i]:(dynwindow$x[i] + dynwindow$y[i] - 1), 5] # Optional: include error on d18Oc
}else{
D_err <- rep(0, dynwindow$y)
O_err <- rep(0, dynwindow$y)
MC <- 0
}
sinlist <- sinreg(Dsam, Osam) # Run sinusoidal regression to find initial parameter values
# Estimate starting parameters from regression results
O_av_start <- sinlist[[1]][1] # Export starting value for annual d18O average
O_amp_start <- sinlist[[1]][2] # Export starting value for d18O amplitude
if(mineral == "calcite"){
T_av_start <- 18.03 * 1000 / (1000 * log((O_av_start - (0.97002 * mean(d18Ow) - 29.98)) / 1000 + 1) + 32.42) - 273.15  # Estimate mean temperature. Use Kim and O'Neil (1997) with conversion between VSMOW and VPDB by Brand et al. (2014)
T_amp_start <- 18.03 * 1000 / (1000 * log((O_av_start - O_amp_start - (0.97002 * mean(d18Ow) - 29.98)) / 1000 + 1) + 32.42) - 273.15 - T_av_start # Estimate temperature amplitude. Use Kim and O'Neil (1997) with conversion between VSMOW and VPDB by Brand et al. (2014)
}else if(mineral == "aragonite"){
T_av_start <- 20.6 - 4.34 * (O_av_start - mean(d18Ow) - 0.2) # Estimate mean temperature. Use Grossmann and Ku (1986) modified by Dettmann et al. (1999)
T_amp_start <- 20.6 - 4.34 * (O_av_start - O_amp_start - mean(d18Ow) - 0.2) - T_av_start # Estimate mean temperature. Use Grossmann and Ku (1986) modified by Dettmann et al. (1999)
}else{
print("ERROR: Supplied mineralogy is not recognized")
}
O_pha_start <- sinlist[[1]][4] %% sinlist[[1]][3] # Estimate position (in depth of the first peak in d18O)
O_peak <- O_pha_start + Dsam[1] # Find position of d18O peak in distance domain
O_per_start <- sinlist[[1]][3] # Export starting value for period in distance domain
T_pha_start <- ((O_pha_start - 0.5 * O_per_start) %% O_per_start) / O_per_start * T_per # Estimate position of first peak in temperature (low in d18O) relative to annual cycle (days)
G_av_start <- O_per_start / G_per # Estimate average growth rate in distance/day
years <- ceiling((diff(range(Dsam)) / O_per_start - 1) / 2) * 2 + 1 # Find next odd number to expand the number of simulated years to cover full window
# Collate starting parameters
par0 <- c(
T_amp = T_amp_start,
T_pha = T_pha_start,
T_av = T_av_start,
G_amp = G_av_start / 2, # Start by estimating growth rate changes by half the average
G_pha = T_pha_start, # Start by estimating that the peak in growth rate coincides with the peak in temperature
G_av = G_av_start,
G_skw = 50 # Start with a no skew
)
par0
paru
parl
# Collate lower boundaries of parameters
parl <- c(
T_amp = 0, # Minimum T amplitude in degrees C
T_pha = 0, # Minimum phase in days
T_av = -4, # Minimum average T in degrees C
G_amp = 0, # Minimum seasonal GR range in um/d
G_pha = 0, # Minimum GR phase in days
G_av = -1 * GRavmax, # Minimum average GR in um/d.
G_skw = 0 # Minimum skew factor
)
# Collate upper boundaries of parameters
paru <- c(
T_amp = 15, # Maximum T amplitude in degrees C
T_pha = 365, # Maximum phase in days
T_av = 60, # Maximum average T in degrees C
G_amp = 2 * GRavmax, # Maximum seasonal GR range in um/d
G_pha = 365, # Maximum GR phase in days
G_av = GRavmax, # Maximum average GR in um/d (based on conservative boundaries of YEARMARKER indicators)
G_skw = 100 # Maximum skew factor
)
invisible(capture.output( # Suppress the details on converging SCEUA
sceua_list <- rtop::sceua(growth_model,
par0,
T_per = T_per,
G_per = G_per,
years = years,
t_int = t_int,
mineral = mineral,
d18Ow = d18Ow,
Dsam = Dsam,
Osam = Osam,
t_maxtemp = t_maxtemp,
parl,
paru,
maxn,
kstop,
pcento,
ngs,
iniflg = iniflg,
peps = peps,
implicit = function(pars){sum(pars[4]/2, pars[6]) < 1} # Make sure that the cumulative GR curve is not located below 0 (if G_av < - G_amp / 2)
)
))
par1 <- sceua_list[[1]] # Eport parameters of final model
names(par1) <- names(par0)
par1
file.exists("~/.ssh/id_rsa.pub")
